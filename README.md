## üìÅ Data
 ## Objectif du projet
 
 Les fichiers de donn√©es n√©cessaires pour entra√Æner et tester le mod√®le ne sont **pas inclus dans le d√©p√¥t Git** pour des raisons de taille et de confidentialit√©.
 Ce projet vise √† pr√©dire si une tumeur du sein est b√©nigne ou maligne √† partir de donn√©es m√©dicales extraites d‚Äôimages (ponction √† l‚Äôaiguille fine). Le probl√®me est formul√© comme une t√¢che de classification binaire supervis√©e.
 
 ---
 
 ## Data utilis√©es
 
 Le jeu de donn√©es utilis√© provient du dataset *Breast Cancer Wisconsin (Diagnostic)*, disponible publiquement sur Kaggle. Les fichiers de donn√©es n√©cessaires pour entra√Æner et tester le mod√®le ne sont **pas inclus dans le d√©p√¥t Git** pour des raisons de taille et de confidentialit√©.
 ‚û°Ô∏è Vous pouvez les t√©l√©charger ici : [Lien vers le dossier Google Drive](https://drive.google.com/drive/folders/12JTnZtRQbY2GckIkGjPtzhvGKnOrSTf8?usp=share_link)
 
 Une fois les fichiers t√©l√©charg√©s, placez-les dans le dossier suivant :
 Chaque ligne correspond √† une tumeur, et les 30 variables num√©riques repr√©sentent diff√©rentes caract√©ristiques des cellules (par exemple : rayon, texture, p√©rim√®tre, sym√©trie, etc.). La variable cible est `diagnosis`, indiquant si la tumeur est b√©nigne (0) ou maligne (1).
 
 Nous avons utilis√© ce dataset dans trois versions diff√©rentes :
 - Une version propre `Sans_bruit.ipynb`, sans bruit, pour √©tablir une premi√®re baseline.
 - Une version modifi√©e avec des valeurs manquantes `Avec_bruit_NaN_drop.ipynb` ins√©r√©es al√©atoirement, puis supprim√©es via `dropna`.
 - Une derni√®re version avec les m√™mes `NaN`,`Avec_bruit_NaN_imputation.ipynb` mais cette fois imput√©es automatiquement en fonction du type de variable (moyenne, m√©diane ou KNN).
 
 Cela nous a permis d‚Äôanalyser non seulement les performances des mod√®les dans des conditions id√©ales, mais aussi leur robustesse face √† des donn√©es incompl√®tes, ce qui est plus proche de la r√©alit√© en contexte m√©dical.
 
 ---
 
 ## M√©thodes de machine learning utilis√©es
 
 Dans notre projet, on a test√© trois mod√®les de classification supervis√©e pour pr√©dire si une tumeur est maligne ou b√©nigne. Le but √©tait de comparer leurs performances, d‚Äôabord sur les donn√©es sans bruit, puis sur des versions du dataset modifi√©es avec du bruit.
 
 - **R√©gression logistique** :  
   C‚Äôest le mod√®le le plus simple, mais souvent tr√®s efficace. On l‚Äôa utilis√© comme mod√®le de r√©f√©rence (baseline), car il est rapide √† entra√Æner et permet de bien comprendre l‚Äôimpact de chaque variable. Malgr√© sa simplicit√©, il a donn√© d‚Äôexcellents r√©sultats sur notre jeu de donn√©es propre.
 
 - **Random Forest** :  
   Ce mod√®le est compos√© de plusieurs arbres de d√©cision, ce qui le rend tr√®s robuste, m√™me si les donn√©es sont bruit√©es ou qu‚Äôil y a des outliers. Il permet aussi de savoir quelles variables sont les plus importantes pour la pr√©diction. On l‚Äôa choisi pour tester un mod√®le plus complexe et non lin√©aire. Il a bien r√©sist√© √† l‚Äôintroduction de NaN, notamment gr√¢ce √† son fonctionnement en ensemble.
 
 - **SVM (Support Vector Machine)** :  
   Le SVM est un mod√®le qui marche bien quand les classes sont bien s√©par√©es, ce qui est le cas ici avec certaines variables tr√®s discriminantes. On a test√© diff√©rents noyaux (lin√©aire et RBF). Il est un peu plus long √† entra√Æner mais ses performances ont √©t√© tr√®s proches de celles des autres mod√®les.
 
 On a utilis√© `GridSearchCV` avec validation crois√©e pour trouver les meilleurs hyperparam√®tres pour chaque mod√®le. Tous les mod√®les ont √©t√© √©valu√©s avec **accuracy, precision, recall et F1-score**. Magr√© de bons r√©sultats il est important de bien √©quilibrer les faux positifs et les faux n√©gatifs car nous sommes dans un contexte m√©dical.
 
 
 ---